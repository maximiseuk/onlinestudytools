{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "server ready code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZaW8ev2BVib",
        "colab_type": "code",
        "outputId": "00c839e5-44bf-4d8d-af5f-cec74098a43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "pip install firebase_admin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting firebase_admin\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/b1/ba41c23eb0f7895a4db5a03255bfeec0f54ee8b70374dc68ff2586cafaa5/firebase_admin-3.2.1-py2.py3-none-any.whl (82kB)\n",
            "\r\u001b[K     |████                            | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.1MB/s \n",
            "\u001b[?25hCollecting cachecontrol>=0.12.4\n",
            "  Downloading https://files.pythonhosted.org/packages/18/71/0a9df4206a5dc5ae7609c41efddab2270a2c1ff61d39de7591dc7302ef89/CacheControl-0.12.6-py2.py3-none-any.whl\n",
            "Collecting google-cloud-firestore>=1.4.0; platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/b1/ef2095d777ca2505efa8182bea155f2ce8bab099224579feb1d309449076/google_cloud_firestore-1.6.1-py2.py3-none-any.whl (333kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.7.11)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.15.0)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.12.0)\n",
            "Collecting google-cloud-storage>=1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/6d/75c2a47af99d15aa8b4de4e66226c128e623f8c9d3e27a8588368ccc38fc/google_cloud_storage-1.25.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cachecontrol>=0.12.4->firebase_admin) (2.21.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from cachecontrol>=0.12.4->firebase_admin) (0.5.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-cloud-firestore>=1.4.0; platform_python_implementation != \"PyPy\"->firebase_admin) (2018.9)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-firestore>=1.4.0; platform_python_implementation != \"PyPy\"->firebase_admin) (1.0.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (1.4.2)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (42.0.2)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (3.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (1.6.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (1.15.0)\n",
            "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.4->firebase_admin) (2.8)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (0.2.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (0.4.8)\n",
            "\u001b[31mERROR: google-cloud-storage 1.25.0 has requirement google-auth<2.0dev,>=1.9.0, but you'll have google-auth 1.4.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-storage 1.25.0 has requirement google-cloud-core<2.0dev,>=1.2.0, but you'll have google-cloud-core 1.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-bigquery 1.21.0 has requirement google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you'll have google-resumable-media 0.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cachecontrol, google-cloud-firestore, google-resumable-media, google-cloud-storage, firebase-admin\n",
            "  Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Found existing installation: google-cloud-storage 1.16.2\n",
            "    Uninstalling google-cloud-storage-1.16.2:\n",
            "      Successfully uninstalled google-cloud-storage-1.16.2\n",
            "Successfully installed cachecontrol-0.12.6 firebase-admin-3.2.1 google-cloud-firestore-1.6.1 google-cloud-storage-1.25.0 google-resumable-media-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QbppvorBYw9",
        "colab_type": "code",
        "outputId": "b6eecb1a-8889-4293-c87b-03caae553bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "from keras.layers import Dense, LSTM, Input, Dropout, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "import numpy as np\n",
        "import random as rand\n",
        "from math import log10, log\n",
        "import datetime\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, storage\n",
        "from urllib.request import urlretrieve\n",
        "from flask import Flask, request\n",
        "import json\n",
        "import threading\n",
        "import requests\n",
        "\n",
        "def retrain(model, data, epochs):\n",
        "  x_train = data[0]\n",
        "  y_train = data[1]\n",
        "  model.fit(np.array(x_train), np.array(y_train), epochs=epochs)\n",
        "  return model\n",
        "\n",
        "def predict(model, previous_grades, required_grades, timesteps):\n",
        "  variation = 0.1\n",
        "  generations = 3\n",
        "  best = [0 if required_grades[i] == 0 else required_grades[i] - previous_grades[i] for i in range(15)]\n",
        "  best.append(1)\n",
        "  variations = [0 if i == 0 else variation for i in previous_grades]\n",
        "  variations.append(variation)\n",
        "  random_outputs, no_tries = [], 30\n",
        "  for output in range(no_tries):\n",
        "    temp = []\n",
        "    for i in range(timesteps):\n",
        "      index = np.argmax(np.random.normal(best, variations))\n",
        "      temp.append(np.array([0 if i != index else 1 for i in range(16)]))\n",
        "    random_outputs.append(np.asarray(temp))\n",
        "  errors = []\n",
        "  for output in random_outputs:\n",
        "    y_true, y_pred = required_grades, model.predict(np.array([output]))[0]\n",
        "    error = sum([((y_true[i] - y_pred[i] + abs(y_true[i] - y_pred[i])) ** 2) / 4 for i in range(len(y_true))])\n",
        "    errors.append(error)\n",
        "  best = random_outputs[np.argmin(errors)]\n",
        "  for i in range(generations - 1):\n",
        "    random_outputs, no_tries = [best], 30\n",
        "    for output in range(no_tries):\n",
        "      temp = []\n",
        "      for i in range(timesteps):\n",
        "        index = np.argmax(np.random.normal(best[i], variations))\n",
        "        temp.append(np.array([0 if i != index else 1 for i in range(16)]))\n",
        "      random_outputs.append(np.asarray(temp))\n",
        "    errors = []\n",
        "    for output in random_outputs:\n",
        "      y_true, y_pred = required_grades, model.predict(np.array([output]))[0]\n",
        "      error = sum([((y_true[i] - y_pred[i] + abs(y_true[i] - y_pred[i])) ** 2) / 4 for i in range(len(y_true))])\n",
        "      errors.append(error)\n",
        "    best = random_outputs[np.argmin(errors)]\n",
        "  return best\n",
        "\n",
        "def start(subjects):\n",
        "  attainments = [5,6,7,8]\n",
        "  models = []\n",
        "  for attainment in attainments:\n",
        "    x_train, y_train, x_test, y_test = simulate_users(attainment, subjects)\n",
        "    input_shape = None, x_train.shape[2]\n",
        "    output_shape = y_train.shape[1] \n",
        "    model = build_model(input_shape, output_shape)\n",
        "    model.fit(x_train, y_train, epochs=250, batch_size=2800, validation_data=(x_test, y_test))\n",
        "    models.append(model)\n",
        "  return models\n",
        "\n",
        "def simulate_users(attainment, subjects):\n",
        "  variation = 0\n",
        "  datapoints, periods = 3000, 10\n",
        "  x, subject_idxs = generate_input_data(subjects, periods, datapoints, attainment)\n",
        "  y = generate_output_data(x, attainment, variation, subject_idxs)\n",
        "  y = format_output_data(y)\n",
        "  x_test, x_train = x[:200], x[200:]\n",
        "  y_test, y_train = y[:200], y[200:]\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "def build_model(input_shape, output_shape):\n",
        "  input_subject = Input(shape=(input_shape))\n",
        "  layer_1 = Bidirectional(LSTM(128, recurrent_dropout=0.7))(input_subject)\n",
        "  output = Dense(output_shape, activation='sigmoid')(layer_1)\n",
        "  model = Model(input_subject, output)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def generate_input_data(subjects, periods, datapoints, attainment):\n",
        "  x, list_of_subject_idxs = [], []\n",
        "  for i in range(datapoints):\n",
        "    subject_idxs = rand.sample(range(15), subjects)\n",
        "    subject_idxs_with_rests = [i for i in subject_idxs]\n",
        "    subject_idxs_with_rests.append(15)\n",
        "    list_of_subject_idxs.append(subject_idxs)\n",
        "    datapoint = []\n",
        "    for i in range(periods):\n",
        "      subject_idx = rand.choice(subject_idxs_with_rests)\n",
        "      subject_ohe = np.linspace(0, 0, 16)\n",
        "      subject_ohe[subject_idx] = 1\n",
        "      datapoint.append(subject_ohe)\n",
        "    datapoint = np.asarray(datapoint)\n",
        "    x.append(datapoint)\n",
        "  x = np.asarray(x)\n",
        "  return x, list_of_subject_idxs\n",
        "\n",
        "def generate_output_data(x, attainment, variation, subject_idxs):\n",
        "  dist_weighting = -0.02\n",
        "  adj_break_weighting = 0.6\n",
        "  adj_subj_weighting = -0.2\n",
        "  y = []\n",
        "  for j, datapoint in enumerate(x):\n",
        "    length = len(datapoint)\n",
        "    efficient_time_studied, grade = [0 for i in range(16)], [0 for i in range(15)]\n",
        "    for i, period in enumerate(datapoint):\n",
        "      distance = length - i\n",
        "      rest, same = 0, 0\n",
        "      if np.argmax(datapoint[i - 1]) == 15:\n",
        "        rest = 1\n",
        "      elif np.argmax(datapoint[i - 1]) == np.argmax(period):\n",
        "        same = 1\n",
        "      efficient_time_studied[np.argmax(period)] += 1 + dist_weighting * distance + adj_break_weighting * rest + adj_subj_weighting * same\n",
        "    for i in subject_idxs[j]:\n",
        "      grade[i] = np.random.normal((2.37089 + 0.602646 * attainment + (3.63039 - 0.330035 * attainment) * log(0.3 + 0.9 * efficient_time_studied[i])), variation)\n",
        "    for i in range(len(grade)):\n",
        "      if grade[i] == 0.:\n",
        "        grade[i] = 5.\n",
        "    y.append(grade)\n",
        "  y = np.asarray(y)\n",
        "  return y\n",
        "\n",
        "def format_output_data(y_unformatted):\n",
        "  y_formatted = y_unformatted / 9\n",
        "  return y_formatted\n",
        "\n",
        "def generate_timetable(inputs):\n",
        "  epochs = len(inputs[\"training_data\"][\"x\"]) * 5 ## this multiplier can be optimised\n",
        "  if inputs[\"training_data\"][\"x\"] != []:\n",
        "    model = retrain(load_model(\"model_attainment_\" + inputs[\"attainment\"] + \".h5\"), (inputs[\"training_data\"][\"x\"], inputs[\"training_data\"][\"y\"]), epochs)\n",
        "  else:\n",
        "    model = load_model(\"model_attainment_\" + inputs[\"attainment\"] + \".h5\")\n",
        "  output = predict(model, inputs[\"prediction_data\"][\"past_grades\"], inputs[\"prediction_data\"][\"required_grades\"], inputs[\"prediction_data\"][\"hours\"])\n",
        "  return output\n",
        "\n",
        "credentials_for_json = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"maximise-uk\",\n",
        "  \"private_key_id\": \"ee4f4bfedd72bcc729c76c1e0c67d5c01e5b96b9\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDZtZE8B2j6HUFd\\nLpmF2EoKZmqpVlwLR/ymi8U+06DZYlgL6KW+cjArrxglibMw6p8shgJxkFh5DZXS\\nk02wPCJrmKC+7wIIhPGiTHs0ji2b7RisEZl4Vgu2cdIR5IowMtds6HxhqjeCdVc4\\nIZ5VeiAqyA9gQW/thcTG7OcX0tcEynOYz9KuaCnWZYgG93Tl+aQQKm+mCsu3GleV\\ngXklS0sjB9HkevLaxcQLoCcg68Se7rSSWSrBguOSZ3SPjdvgJpsr09UoTA+9Spbu\\nRpC9avXoxrA0Tx+X0Z9rvRF8jYxOQwL2OkLCrpK3TCYCarbLUqax0oKtZ0LpBDcy\\nke/efi3zAgMBAAECggEAJ9VPwHL+oxytM/Ztwo6DZYm9pEQXzTybnoFeUpN4D64t\\nu+gSQ1kzNRrxSRT7w0x6WTQfyFWHyoZQzlmDUmZ+Sb+AUc77SUHB0Fc8B66n66qi\\n5ADIWrsro3MJ45o0KoNy5QtYjqoNRAJiNfP4u1z/+7PlFFCEwSnDij4YPkSmcMqf\\nnHyUPwxPvcUp2CAkeKjrV3UXEjdQ0wkh4hv6yMcXnGGDNknwEAEQ7may+BA81eAW\\nYky+ItP4qAauXHxJQBNG9iy9Win+BXQzFanF3ZmpyRtPjsfShuuFUNRncDt64E80\\nO7esMEQdjIlhMeSwZkWVob1U0l7nH5PCyRjfOwLxIQKBgQDu6Oq2eFmuUchBTZGa\\na/gAQ171g3dPCA4nhMoZM+beJM7tKrpTGb2S0B5yHpBd8llWkBIHnmEoFgPOZgPa\\nIt2GEK/ntOsvM4DYUSA6EizFUwLSLUDDIE34mvPehfakLM8Wh0Li/clzlZ58pvBv\\nhkVl3P/WBLLV8dDTalCNtGgS8QKBgQDpSGkecH/JuAwGB47fxoOdWCzs8f+DjP8P\\nRH3MQNtwp7DSSLRXNc9niQM/Ot1Fc8DOvxwxxUyR9iMqcHKiiPJsts4HItHq/WlR\\nxyAoRNGewKdk+Y4hZhIh0rEna8cce9ggNRGiw8HK2g2GnbomPj3eJdK5/MNWmkT+\\nyBIQ+a8HIwKBgA0fnkUHt2Vr+KQdrrHc3HKnQMAbyKH+v0hMcw2PXE83lmZQwotu\\nDovSAtoh86w1c9LddyAUAyJAk1TzJaMF50VGBWOk/IZLPfij/DE0bmEofi8tbTFK\\nxP2zBVJj6Xh7PaTvKS1u43IF9f7C7NIzffxqd2M6Ptihv+bdIC+oiU8BAoGBAOWT\\nzV+XdysdZTfJ2GGBC6WdURkeT0c3SwvLa8HHUi3b2bgYtOHeou5ReFCRrZDcCbNt\\ngGG6uVAr2w+4+hfajjlO7hM3wT5xhWRlgtAeaezBy/sjXSyhNtbyckVJW/o8JsYL\\nc/+qht0LGqSQNNHODzTAJFHE3rgruhrC6oSqNAXhAoGAXzB4POvZDXNTNRIAhMJ4\\no1PCooAq6K3WmGyAOV7+hQxS9IyShhIIqTG3B+fXoEgz/aaHwp+w1c83MSiiQWH1\\nZh0mB/Eer50iEPfECyhF8sPTW+Hk5KMUQSTZkkVximpQ7rszrb4JOrsjegCBP01s\\nOynEJrkUc6IZH/a/LLy1+90=\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"firebase-adminsdk-zduqr@maximise-uk.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"101775960412756890600\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-zduqr%40maximise-uk.iam.gserviceaccount.com\"\n",
        "}\n",
        "\n",
        "with open(\"credentials.json\", \"w\") as write_file:\n",
        "    json.dump(credentials_for_json, write_file)\n",
        "\n",
        "cred = credentials.Certificate(\"credentials.json\")\n",
        "app = firebase_admin.initialize_app(cred, {\n",
        "    'storageBucket': 'maximise-uk.appspot.com',\n",
        "}, name='storage')\n",
        "bucket = storage.bucket(app=app)\n",
        "for i in range(5, 9):\n",
        "  blob = bucket.blob(f\"model_attainment_{i}.h5\")\n",
        "  urlretrieve(blob.generate_signed_url(datetime.timedelta(seconds=300), method='GET'), f'model_attainment_{i}.h5')\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def generate_ml():\n",
        "    inputs = request.get_json()\n",
        "    output = generate_timetable(inputs)\n",
        "    return str(output)\n",
        "threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':80}).start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkEO7v0UBdel",
        "colab_type": "code",
        "outputId": "79a9df4f-6616-4c0c-da39-d589e0b31c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inputs = {\n",
        "  \"attainment\": \"8\",\n",
        "  \"training_data\": {\n",
        "      \"x\": [[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]],\n",
        "      \"y\": [[8, 5, 5, 5, 8, 9, 7, 5, 5, 5, 5, 5, 8, 5, 5]]\n",
        "  },\n",
        "  \"prediction_data\": {\n",
        "    \"past_grades\": [6, 0, 0, 0, 6, 6, 6, 0, 0, 0, 0, 0, 6, 0, 0],\n",
        "    \"required_grades\": [7, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 7, 0, 0],\n",
        "    \"hours\": 20\n",
        "  }\n",
        "}\n",
        "r = requests.post(\"http://172.28.0.2/\", json = inputs)\n",
        "print(r.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 1s/step - loss: 241.2777 - acc: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 241.2545 - acc: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 241.3365 - acc: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 241.2930 - acc: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 241.2658 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [20/Jan/2020 12:55:56] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}