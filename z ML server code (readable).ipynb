{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ram lower server ready code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZaW8ev2BVib",
        "colab_type": "code",
        "outputId": "5920fb97-7dc8-4723-8b68-98963c6d276b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "pip install firebase_admin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting firebase_admin\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/0a/98410db0d119cd1993b116489191183cf894f26d7061a87a4a1c6a240cf1/firebase_admin-4.0.0-py3-none-any.whl (82kB)\n",
            "\r\u001b[K     |████                            | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.7.11)\n",
            "Collecting cachecontrol>=0.12.6\n",
            "  Downloading https://files.pythonhosted.org/packages/18/71/0a9df4206a5dc5ae7609c41efddab2270a2c1ff61d39de7591dc7302ef89/CacheControl-0.12.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.6/dist-packages (from firebase_admin) (1.16.0)\n",
            "Collecting google-cloud-storage>=1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/67/80761781f813ffbf8bc1db7270b6d23de7a96468da4601de3bf2e5e1d829/google_cloud_storage-1.26.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n",
            "\u001b[?25hCollecting google-cloud-firestore>=1.4.0; platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/a3/bcde6f5ce12314d6e392c61489c1e5f4b59d2bf23e8e8613a257d6d4c993/google_cloud_firestore-1.6.2-py2.py3-none-any.whl (335kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (1.7.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.11.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.0.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.7.8->firebase_admin) (1.12.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from cachecontrol>=0.12.6->firebase_admin) (0.5.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cachecontrol>=0.12.6->firebase_admin) (2.21.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (45.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (1.51.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (2018.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\"->firebase_admin) (1.27.1)\n",
            "Collecting google-cloud-core<2.0dev,>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\n",
            "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/35/9e/f73325d0466ce5bdc36333f1aeb2892ead7b76e79bdb5c8b0493961fa098/google_resumable_media-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (3.1.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.6->firebase_admin) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.6->firebase_admin) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.6->firebase_admin) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cachecontrol>=0.12.6->firebase_admin) (2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.4.1->google-api-python-client>=1.7.8->firebase_admin) (0.4.8)\n",
            "\u001b[31mERROR: google-cloud-storage 1.26.0 has requirement google-auth<2.0dev,>=1.11.0, but you'll have google-auth 1.7.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-bigquery 1.21.0 has requirement google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you'll have google-resumable-media 0.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cachecontrol, google-cloud-core, google-resumable-media, google-cloud-storage, google-cloud-firestore, firebase-admin\n",
            "  Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Found existing installation: google-cloud-storage 1.16.2\n",
            "    Uninstalling google-cloud-storage-1.16.2:\n",
            "      Successfully uninstalled google-cloud-storage-1.16.2\n",
            "Successfully installed cachecontrol-0.12.6 firebase-admin-4.0.0 google-cloud-core-1.3.0 google-cloud-firestore-1.6.2 google-cloud-storage-1.26.0 google-resumable-media-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QbppvorBYw9",
        "colab_type": "code",
        "outputId": "80afd4e9-a3e6-479d-b97e-f9a454e6cda4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "from keras.layers import Dense, LSTM, Input, Dropout, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "from numpy import asarray, argmax, argmin, linspace\n",
        "from numpy.random import normal\n",
        "from random import randint, choice, sample\n",
        "from math import log10, log\n",
        "from datetime import timedelta\n",
        "from firebase_admin import credentials, storage, initialize_app\n",
        "from urllib.request import urlretrieve\n",
        "from flask import Flask, request\n",
        "from json import dump\n",
        "from threading import Thread\n",
        "from requests import post\n",
        "\n",
        "def retrain(model, data, epochs):\n",
        "  x_train = asarray([asarray([asarray(j) for j in i]) for i in data[0]])\n",
        "  y_train = data[1]\n",
        "  max_length = max([len(i) for i in x_train])\n",
        "  base_array = [0 for i in range(16)]\n",
        "  base_array[15] = 1\n",
        "  base_array = asarray([base_array for i in range(max_length)])\n",
        "  for i in range(len(x_train)):\n",
        "    temp = x_train[i]\n",
        "    x_train[i] = base_array.copy()\n",
        "    x_train[i][:temp.shape[0],:temp.shape[1]] = temp\n",
        "  x_train = x_train.tolist()\n",
        "  model.fit(asarray(x_train), asarray(y_train), epochs=epochs)\n",
        "  return model\n",
        "\n",
        "def predict(model, previous_grades, required_grades, timesteps):\n",
        "  variation = 0.1\n",
        "  generations = 3\n",
        "  best = [0 if required_grades[i] == 0 else required_grades[i] - previous_grades[i] for i in range(15)]\n",
        "  best.append(1)\n",
        "  variations = [0 if i == 0 else variation for i in previous_grades]\n",
        "  variations.append(variation)\n",
        "  random_outputs, no_tries = [], 30\n",
        "  for output in range(no_tries):\n",
        "    temp = []\n",
        "    for i in range(timesteps):\n",
        "      index = argmax(normal(best, variations))\n",
        "      temp.append(asarray([0 if i != index else 1 for i in range(16)]))\n",
        "    random_outputs.append(asarray(temp))\n",
        "  errors = []\n",
        "  for output in random_outputs:\n",
        "    y_true, y_pred = required_grades, model.predict(asarray([output]))[0]\n",
        "    error = sum([((y_true[i] - y_pred[i] + abs(y_true[i] - y_pred[i])) ** 2) / 4 for i in range(len(y_true))])\n",
        "    errors.append(error)\n",
        "  best = random_outputs[argmin(errors)]\n",
        "  for i in range(generations - 1):\n",
        "    random_outputs, no_tries = [best], 30\n",
        "    for output in range(no_tries):\n",
        "      temp = []\n",
        "      for i in range(timesteps):\n",
        "        index = argmax(normal(best[i], variations))\n",
        "        temp.append(asarray([0 if i != index else 1 for i in range(16)]))\n",
        "      random_outputs.append(asarray(temp))\n",
        "    errors = []\n",
        "    for output in random_outputs:\n",
        "      y_true, y_pred = required_grades, model.predict(asarray([output]))[0]\n",
        "      error = sum([((y_true[i] - y_pred[i] + abs(y_true[i] - y_pred[i])) ** 2) / 4 for i in range(len(y_true))])\n",
        "      errors.append(error)\n",
        "    best = random_outputs[argmin(errors)]\n",
        "  return best\n",
        "\n",
        "def start(subjects):\n",
        "  attainments = [5,6,7,8]\n",
        "  models = []\n",
        "  for attainment in attainments:\n",
        "    x_train, y_train, x_test, y_test = simulate_users(attainment, subjects)\n",
        "    input_shape = None, x_train.shape[2]\n",
        "    output_shape = y_train.shape[1] \n",
        "    model = build_model(input_shape, output_shape)\n",
        "    model.fit(x_train, y_train, epochs=250, batch_size=2800, validation_data=(x_test, y_test))\n",
        "    models.append(model)\n",
        "  return models\n",
        "\n",
        "def simulate_users(attainment, subjects):\n",
        "  variation = 0\n",
        "  datapoints, periods = 3000, 10\n",
        "  x, subject_idxs = generate_input_data(subjects, periods, datapoints, attainment)\n",
        "  y = generate_output_data(x, attainment, variation, subject_idxs)\n",
        "  y = format_output_data(y)\n",
        "  x_test, x_train = x[:200], x[200:]\n",
        "  y_test, y_train = y[:200], y[200:]\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "def build_model(input_shape, output_shape):\n",
        "  input_subject = Input(shape=(input_shape))\n",
        "  layer_1 = Bidirectional(LSTM(128, recurrent_dropout=0.7))(input_subject)\n",
        "  output = Dense(output_shape, activation='sigmoid')(layer_1)\n",
        "  model = Model(input_subject, output)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def generate_input_data(subjects, periods, datapoints, attainment):\n",
        "  x, list_of_subject_idxs = [], []\n",
        "  for i in range(datapoints):\n",
        "    subject_idxs = sample(range(15), subjects)\n",
        "    subject_idxs_with_rests = [i for i in subject_idxs]\n",
        "    subject_idxs_with_rests.append(15)\n",
        "    list_of_subject_idxs.append(subject_idxs)\n",
        "    datapoint = []\n",
        "    for i in range(periods):\n",
        "      subject_idx = choice(subject_idxs_with_rests)\n",
        "      subject_ohe = linspace(0, 0, 16)\n",
        "      subject_ohe[subject_idx] = 1\n",
        "      datapoint.append(subject_ohe)\n",
        "    datapoint = asarray(datapoint)\n",
        "    x.append(datapoint)\n",
        "  x = asarray(x)\n",
        "  return x, list_of_subject_idxs\n",
        "\n",
        "def generate_output_data(x, attainment, variation, subject_idxs):\n",
        "  dist_weighting = -0.02\n",
        "  adj_break_weighting = 0.6\n",
        "  adj_subj_weighting = -0.2\n",
        "  y = []\n",
        "  for j, datapoint in enumerate(x):\n",
        "    length = len(datapoint)\n",
        "    efficient_time_studied, grade = [0 for i in range(16)], [0 for i in range(15)]\n",
        "    for i, period in enumerate(datapoint):\n",
        "      distance = length - i\n",
        "      rest, same = 0, 0\n",
        "      if argmax(datapoint[i - 1]) == 15:\n",
        "        rest = 1\n",
        "      elif argmax(datapoint[i - 1]) == argmax(period):\n",
        "        same = 1\n",
        "      efficient_time_studied[argmax(period)] += 1 + dist_weighting * distance + adj_break_weighting * rest + adj_subj_weighting * same\n",
        "    for i in subject_idxs[j]:\n",
        "      grade[i] = normal((2.37089 + 0.602646 * attainment + (3.63039 - 0.330035 * attainment) * log(0.3 + 0.9 * efficient_time_studied[i])), variation)\n",
        "    for i in range(len(grade)):\n",
        "      if grade[i] == 0.:\n",
        "        grade[i] = 5.\n",
        "    y.append(grade)\n",
        "  y = asarray(y)\n",
        "  return y\n",
        "\n",
        "def format_output_data(y_unformatted):\n",
        "  y_formatted = y_unformatted / 9\n",
        "  return y_formatted\n",
        "\n",
        "def generate_timetable(inputs):\n",
        "  epochs = len(inputs[\"training_data\"][\"x\"]) * 5 ## this multiplier can be optimised\n",
        "  if inputs[\"training_data\"][\"x\"] != []:\n",
        "    model = retrain(load_model(\"model_attainment_\" + inputs[\"attainment\"] + \".h5\"), (inputs[\"training_data\"][\"x\"], inputs[\"training_data\"][\"y\"]), epochs)\n",
        "  else:\n",
        "    model = load_model(\"model_attainment_\" + inputs[\"attainment\"] + \".h5\")\n",
        "  output = predict(model, inputs[\"prediction_data\"][\"past_grades\"], inputs[\"prediction_data\"][\"required_grades\"], inputs[\"prediction_data\"][\"hours\"])\n",
        "  return output\n",
        "\n",
        "credentials_for_json = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"maximise-uk\",\n",
        "  \"private_key_id\": \"ee4f4bfedd72bcc729c76c1e0c67d5c01e5b96b9\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDZtZE8B2j6HUFd\\nLpmF2EoKZmqpVlwLR/ymi8U+06DZYlgL6KW+cjArrxglibMw6p8shgJxkFh5DZXS\\nk02wPCJrmKC+7wIIhPGiTHs0ji2b7RisEZl4Vgu2cdIR5IowMtds6HxhqjeCdVc4\\nIZ5VeiAqyA9gQW/thcTG7OcX0tcEynOYz9KuaCnWZYgG93Tl+aQQKm+mCsu3GleV\\ngXklS0sjB9HkevLaxcQLoCcg68Se7rSSWSrBguOSZ3SPjdvgJpsr09UoTA+9Spbu\\nRpC9avXoxrA0Tx+X0Z9rvRF8jYxOQwL2OkLCrpK3TCYCarbLUqax0oKtZ0LpBDcy\\nke/efi3zAgMBAAECggEAJ9VPwHL+oxytM/Ztwo6DZYm9pEQXzTybnoFeUpN4D64t\\nu+gSQ1kzNRrxSRT7w0x6WTQfyFWHyoZQzlmDUmZ+Sb+AUc77SUHB0Fc8B66n66qi\\n5ADIWrsro3MJ45o0KoNy5QtYjqoNRAJiNfP4u1z/+7PlFFCEwSnDij4YPkSmcMqf\\nnHyUPwxPvcUp2CAkeKjrV3UXEjdQ0wkh4hv6yMcXnGGDNknwEAEQ7may+BA81eAW\\nYky+ItP4qAauXHxJQBNG9iy9Win+BXQzFanF3ZmpyRtPjsfShuuFUNRncDt64E80\\nO7esMEQdjIlhMeSwZkWVob1U0l7nH5PCyRjfOwLxIQKBgQDu6Oq2eFmuUchBTZGa\\na/gAQ171g3dPCA4nhMoZM+beJM7tKrpTGb2S0B5yHpBd8llWkBIHnmEoFgPOZgPa\\nIt2GEK/ntOsvM4DYUSA6EizFUwLSLUDDIE34mvPehfakLM8Wh0Li/clzlZ58pvBv\\nhkVl3P/WBLLV8dDTalCNtGgS8QKBgQDpSGkecH/JuAwGB47fxoOdWCzs8f+DjP8P\\nRH3MQNtwp7DSSLRXNc9niQM/Ot1Fc8DOvxwxxUyR9iMqcHKiiPJsts4HItHq/WlR\\nxyAoRNGewKdk+Y4hZhIh0rEna8cce9ggNRGiw8HK2g2GnbomPj3eJdK5/MNWmkT+\\nyBIQ+a8HIwKBgA0fnkUHt2Vr+KQdrrHc3HKnQMAbyKH+v0hMcw2PXE83lmZQwotu\\nDovSAtoh86w1c9LddyAUAyJAk1TzJaMF50VGBWOk/IZLPfij/DE0bmEofi8tbTFK\\nxP2zBVJj6Xh7PaTvKS1u43IF9f7C7NIzffxqd2M6Ptihv+bdIC+oiU8BAoGBAOWT\\nzV+XdysdZTfJ2GGBC6WdURkeT0c3SwvLa8HHUi3b2bgYtOHeou5ReFCRrZDcCbNt\\ngGG6uVAr2w+4+hfajjlO7hM3wT5xhWRlgtAeaezBy/sjXSyhNtbyckVJW/o8JsYL\\nc/+qht0LGqSQNNHODzTAJFHE3rgruhrC6oSqNAXhAoGAXzB4POvZDXNTNRIAhMJ4\\no1PCooAq6K3WmGyAOV7+hQxS9IyShhIIqTG3B+fXoEgz/aaHwp+w1c83MSiiQWH1\\nZh0mB/Eer50iEPfECyhF8sPTW+Hk5KMUQSTZkkVximpQ7rszrb4JOrsjegCBP01s\\nOynEJrkUc6IZH/a/LLy1+90=\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"firebase-adminsdk-zduqr@maximise-uk.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"101775960412756890600\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-zduqr%40maximise-uk.iam.gserviceaccount.com\"\n",
        "}\n",
        "\n",
        "with open(\"credentials.json\", \"w\") as write_file:\n",
        "    dump(credentials_for_json, write_file)\n",
        "\n",
        "cred = credentials.Certificate(\"credentials.json\")\n",
        "app = initialize_app(cred, {\n",
        "    'storageBucket': 'maximise-uk.appspot.com',\n",
        "}, name='storage')\n",
        "bucket = storage.bucket(app=app)\n",
        "for i in range(5, 9):\n",
        "  blob = bucket.blob(f\"model_attainment_{i}.h5\")\n",
        "  urlretrieve(blob.generate_signed_url(timedelta(seconds=300), method='GET'), f'model_attainment_{i}.h5')\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def generate_ml():\n",
        "    inputs = request.get_json()\n",
        "    output = generate_timetable(inputs)\n",
        "    return str({\"output\":output.tolist()})\n",
        "Thread(target=app.run, kwargs={'host':'0.0.0.0','port':80}).start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlwy9FSMwHmr",
        "colab_type": "code",
        "outputId": "f64647d9-a18c-4886-9228-eb54c3982337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inputs = {\n",
        "  \"attainment\": \"8\",\n",
        "  \"training_data\": {\n",
        "      \"x\": [[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
        "      \"y\": [[8, 5, 5, 5, 8, 9, 7, 5, 5, 5, 5, 5, 8, 5, 5], [8, 5, 5, 5, 8, 9, 7, 5, 5, 5, 5, 5, 8, 5, 5]]\n",
        "  },\n",
        "  \"prediction_data\": {\n",
        "    \"past_grades\": [6, 0, 0, 0, 6, 6, 6, 0, 0, 0, 0, 0, 6, 0, 0],\n",
        "    \"required_grades\": [7, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 7, 0, 0],\n",
        "    \"hours\": 20\n",
        "  }\n",
        "}\n",
        "r = post(\"http://172.28.0.2/\", json = inputs)\n",
        "print(r.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 241.9450 - acc: 0.5000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 242.7100 - acc: 0.5000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 242.8346 - acc: 0.5000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 242.6892 - acc: 0.5000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 242.6253 - acc: 0.5000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 242.4051 - acc: 0.5000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 242.3544 - acc: 0.5000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 241.5483 - acc: 0.5000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 241.9719 - acc: 0.5000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 241.4559 - acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [26/Feb/2020 14:32:34] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'output': [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U05dKZgPtCe7",
        "colab_type": "code",
        "outputId": "fc016f1a-f5fe-4d3c-c7a2-919fc629a455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "from numpy import asarray, argmax, argmin\n",
        "from numpy.random import normal\n",
        "from datetime import timedelta\n",
        "from firebase_admin import credentials, storage, initialize_app\n",
        "from firebase_admin.credentials import Certificate\n",
        "from urllib.request import urlretrieve\n",
        "from flask import Flask, request\n",
        "from json import dump\n",
        "from threading import Thread\n",
        "from requests import post\n",
        "\n",
        "def retrain(model, data, epochs):\n",
        "  x_train = asarray([asarray([asarray(j) for j in i]) for i in data[0]])\n",
        "  y_train = data[1]\n",
        "  max_length = max([len(i) for i in x_train])\n",
        "  base_array = [0 for i in range(16)]\n",
        "  base_array[15] = 1\n",
        "  base_array = asarray([base_array for i in range(max_length)])\n",
        "  for i in range(len(x_train)):\n",
        "    temp = x_train[i]\n",
        "    x_train[i] = base_array.copy()\n",
        "    x_train[i][:temp.shape[0],:temp.shape[1]] = temp\n",
        "  x_train = x_train.tolist()\n",
        "  model.fit(asarray(x_train), asarray(y_train), epochs=epochs)\n",
        "  return model\n",
        "\n",
        "def predict(model, previous_grades, required_grades, timesteps):\n",
        "  variation = 0.1\n",
        "  generations = 3\n",
        "  best = [0 if required_grades[i] == 0 else required_grades[i] - previous_grades[i] for i in range(15)]\n",
        "  best.append(1)\n",
        "  variations = [0 if i == 0 else variation for i in previous_grades]\n",
        "  variations.append(variation)\n",
        "  random_outputs, no_tries = [], 30\n",
        "  for output in range(no_tries):\n",
        "    temp = []\n",
        "    for i in range(timesteps):\n",
        "      index = argmax(normal(best, variations))\n",
        "      temp.append(asarray([0 if i != index else 1 for i in range(16)]))\n",
        "    random_outputs.append(asarray(temp))\n",
        "  errors = []\n",
        "  for output in random_outputs:\n",
        "    y_true, y_pred = required_grades, model.predict(asarray([output]))[0]\n",
        "    error = sum([((y_true[i] - y_pred[i] + abs(y_true[i] - y_pred[i])) ** 2) / 4 for i in range(len(y_true))])\n",
        "    errors.append(error)\n",
        "  best = random_outputs[argmin(errors)]\n",
        "  for i in range(generations - 1):\n",
        "    random_outputs, no_tries = [best], 30\n",
        "    for output in range(no_tries):\n",
        "      temp = []\n",
        "      for i in range(timesteps):\n",
        "        index = argmax(normal(best[i], variations))\n",
        "        temp.append(asarray([0 if i != index else 1 for i in range(16)]))\n",
        "      random_outputs.append(asarray(temp))\n",
        "    errors = []\n",
        "    for output in random_outputs:\n",
        "      y_true, y_pred = required_grades, model.predict(asarray([output]))[0]\n",
        "      error = sum([((y_true[i] - y_pred[i] + abs(y_true[i] - y_pred[i])) ** 2) / 4 for i in range(len(y_true))])\n",
        "      errors.append(error)\n",
        "    best = random_outputs[argmin(errors)]\n",
        "  return best\n",
        "\n",
        "def generate_timetable(inputs):\n",
        "  epochs = len(inputs[\"training_data\"][\"x\"]) * 2 ## this multiplier can be optimised\n",
        "  if inputs[\"training_data\"][\"x\"] != []:\n",
        "    model = retrain(load_model(\"model_attainment_\" + inputs[\"attainment\"] + \".h5\"), (inputs[\"training_data\"][\"x\"], inputs[\"training_data\"][\"y\"]), epochs)\n",
        "  else:\n",
        "    model = load_model(\"model_attainment_\" + inputs[\"attainment\"] + \".h5\")\n",
        "  output = predict(model, inputs[\"prediction_data\"][\"past_grades\"], inputs[\"prediction_data\"][\"required_grades\"], inputs[\"prediction_data\"][\"hours\"])\n",
        "  return output\n",
        "\n",
        "credentials_for_json = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"maximise-uk\",\n",
        "  \"private_key_id\": \"ee4f4bfedd72bcc729c76c1e0c67d5c01e5b96b9\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDZtZE8B2j6HUFd\\nLpmF2EoKZmqpVlwLR/ymi8U+06DZYlgL6KW+cjArrxglibMw6p8shgJxkFh5DZXS\\nk02wPCJrmKC+7wIIhPGiTHs0ji2b7RisEZl4Vgu2cdIR5IowMtds6HxhqjeCdVc4\\nIZ5VeiAqyA9gQW/thcTG7OcX0tcEynOYz9KuaCnWZYgG93Tl+aQQKm+mCsu3GleV\\ngXklS0sjB9HkevLaxcQLoCcg68Se7rSSWSrBguOSZ3SPjdvgJpsr09UoTA+9Spbu\\nRpC9avXoxrA0Tx+X0Z9rvRF8jYxOQwL2OkLCrpK3TCYCarbLUqax0oKtZ0LpBDcy\\nke/efi3zAgMBAAECggEAJ9VPwHL+oxytM/Ztwo6DZYm9pEQXzTybnoFeUpN4D64t\\nu+gSQ1kzNRrxSRT7w0x6WTQfyFWHyoZQzlmDUmZ+Sb+AUc77SUHB0Fc8B66n66qi\\n5ADIWrsro3MJ45o0KoNy5QtYjqoNRAJiNfP4u1z/+7PlFFCEwSnDij4YPkSmcMqf\\nnHyUPwxPvcUp2CAkeKjrV3UXEjdQ0wkh4hv6yMcXnGGDNknwEAEQ7may+BA81eAW\\nYky+ItP4qAauXHxJQBNG9iy9Win+BXQzFanF3ZmpyRtPjsfShuuFUNRncDt64E80\\nO7esMEQdjIlhMeSwZkWVob1U0l7nH5PCyRjfOwLxIQKBgQDu6Oq2eFmuUchBTZGa\\na/gAQ171g3dPCA4nhMoZM+beJM7tKrpTGb2S0B5yHpBd8llWkBIHnmEoFgPOZgPa\\nIt2GEK/ntOsvM4DYUSA6EizFUwLSLUDDIE34mvPehfakLM8Wh0Li/clzlZ58pvBv\\nhkVl3P/WBLLV8dDTalCNtGgS8QKBgQDpSGkecH/JuAwGB47fxoOdWCzs8f+DjP8P\\nRH3MQNtwp7DSSLRXNc9niQM/Ot1Fc8DOvxwxxUyR9iMqcHKiiPJsts4HItHq/WlR\\nxyAoRNGewKdk+Y4hZhIh0rEna8cce9ggNRGiw8HK2g2GnbomPj3eJdK5/MNWmkT+\\nyBIQ+a8HIwKBgA0fnkUHt2Vr+KQdrrHc3HKnQMAbyKH+v0hMcw2PXE83lmZQwotu\\nDovSAtoh86w1c9LddyAUAyJAk1TzJaMF50VGBWOk/IZLPfij/DE0bmEofi8tbTFK\\nxP2zBVJj6Xh7PaTvKS1u43IF9f7C7NIzffxqd2M6Ptihv+bdIC+oiU8BAoGBAOWT\\nzV+XdysdZTfJ2GGBC6WdURkeT0c3SwvLa8HHUi3b2bgYtOHeou5ReFCRrZDcCbNt\\ngGG6uVAr2w+4+hfajjlO7hM3wT5xhWRlgtAeaezBy/sjXSyhNtbyckVJW/o8JsYL\\nc/+qht0LGqSQNNHODzTAJFHE3rgruhrC6oSqNAXhAoGAXzB4POvZDXNTNRIAhMJ4\\no1PCooAq6K3WmGyAOV7+hQxS9IyShhIIqTG3B+fXoEgz/aaHwp+w1c83MSiiQWH1\\nZh0mB/Eer50iEPfECyhF8sPTW+Hk5KMUQSTZkkVximpQ7rszrb4JOrsjegCBP01s\\nOynEJrkUc6IZH/a/LLy1+90=\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"firebase-adminsdk-zduqr@maximise-uk.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"101775960412756890600\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-zduqr%40maximise-uk.iam.gserviceaccount.com\"\n",
        "}\n",
        "\n",
        "with open(\"credentials.json\", \"w\") as write_file:\n",
        "    dump(credentials_for_json, write_file)\n",
        "\n",
        "cred = credentials.Certificate(\"credentials.json\")\n",
        "app = initialize_app(cred, {\n",
        "    'storageBucket': 'maximise-uk.appspot.com',\n",
        "}, name='storage')\n",
        "bucket = storage.bucket(app=app)\n",
        "for i in range(5, 9):\n",
        "  blob = bucket.blob(f\"model_attainment_{i}.h5\")\n",
        "  urlretrieve(blob.generate_signed_url(timedelta(seconds=300), method='GET'), f'model_attainment_{i}.h5')\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def generate_ml():\n",
        "    inputs = request.get_json()\n",
        "    output = generate_timetable(inputs)\n",
        "    return str({\"output\":output.tolist()})\n",
        "Thread(target=app.run, kwargs={'host':'0.0.0.0','port':80}).start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIOC6qYK8FGy",
        "colab_type": "code",
        "outputId": "252ce983-ba36-4a7c-f539-e5b393d43f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "inputs = {\n",
        "  \"attainment\": \"8\",\n",
        "  \"training_data\": {\n",
        "      \"x\": [[[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
        "      \"y\": [[8, 5, 5, 5, 8, 9, 7, 5, 5, 5, 5, 5, 8, 5, 5], [8, 5, 5, 5, 8, 9, 7, 5, 5, 5, 5, 5, 8, 5, 5]]\n",
        "  },\n",
        "  \"prediction_data\": {\n",
        "    \"past_grades\": [6, 0, 0, 0, 6, 6, 6, 0, 0, 0, 0, 0, 6, 0, 0],\n",
        "    \"required_grades\": [7, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 7, 0, 0],\n",
        "    \"hours\": 20\n",
        "  }\n",
        "}\n",
        "r = post(\"http://172.28.0.2/\", json = inputs)\n",
        "print(r.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/4\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 242.2230 - acc: 0.5000\n",
            "Epoch 2/4\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 241.9753 - acc: 0.5000\n",
            "Epoch 3/4\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 242.3581 - acc: 0.5000\n",
            "Epoch 4/4\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 242.0287 - acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [26/Feb/2020 14:51:08] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'output': [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6IORZog8May",
        "colab_type": "code",
        "outputId": "de74ca61-a37c-4de7-e7b8-2eef2331df0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "a='credentials.json'\n",
        "Z=abs\n",
        "Y=sum\n",
        "J=len\n",
        "A=range\n",
        "from keras.models import Model,load_model as D\n",
        "from numpy import asarray as B,argmax as Q,argmin as R\n",
        "from numpy.random import normal as S\n",
        "from datetime import timedelta as F\n",
        "from firebase_admin import credentials as G,storage as H,initialize_app as I\n",
        "from firebase_admin.credentials import Certificate\n",
        "from urllib.request import urlretrieve as K\n",
        "from flask import Flask,request as L\n",
        "from json import dump\n",
        "from threading import Thread as M\n",
        "from requests import post\n",
        "def N(model,data,epochs):\n",
        "\tG=model;C=B([B([B(C)for C in A])for A in data[0]]);H=data[1];I=max([J(A)for A in C]);D=[0 for B in A(16)];D[15]=1;D=B([D for B in A(I)])\n",
        "\tfor E in A(J(C)):F=C[E];C[E]=D.copy();C[E][:F.shape[0],:F.shape[1]]=F\n",
        "\tC=C.tolist();G.fit(B(C),B(H),epochs=epochs);return G\n",
        "def O(model,previous_grades,required_grades,timesteps):\n",
        "\tV=timesteps;U=previous_grades;T=model;K=required_grades;W=0.1;X=3;C=[0 if K[B]==0 else K[B]-U[B]for B in A(15)];C.append(1);L=[0 if A==0 else W for A in U];L.append(W);D,M=[],30\n",
        "\tfor F in A(M):\n",
        "\t\tG=[]\n",
        "\t\tfor N in A(V):O=Q(S(C,L));G.append(B([0 if B!=O else 1 for B in A(16)]))\n",
        "\t\tD.append(B(G))\n",
        "\tH=[]\n",
        "\tfor F in D:E,I=K,T.predict(B([F]))[0];P=Y([(E[B]-I[B]+Z(E[B]-I[B]))**2/4 for B in A(J(E))]);H.append(P)\n",
        "\tC=D[R(H)]\n",
        "\tfor N in A(X-1):\n",
        "\t\tD,M=[C],30\n",
        "\t\tfor F in A(M):\n",
        "\t\t\tG=[]\n",
        "\t\t\tfor N in A(V):O=Q(S(C[N],L));G.append(B([0 if B!=O else 1 for B in A(16)]))\n",
        "\t\t\tD.append(B(G))\n",
        "\t\tH=[]\n",
        "\t\tfor F in D:E,I=K,T.predict(B([F]))[0];P=Y([(E[B]-I[B]+Z(E[B]-I[B]))**2/4 for B in A(J(E))]);H.append(P)\n",
        "\t\tC=D[R(H)]\n",
        "\treturn C\n",
        "def P(inputs):\n",
        "\tL='.h5';K='attainment';I='model_attainment_';F='prediction_data';E='x';B='training_data';A=inputs;G=J(A[B][E])*2\n",
        "\tif A[B][E]!=[]:C=N(D(I+A[K]+L),(A[B][E],A[B]['y']),G)\n",
        "\telse:C=D(I+A[K]+L)\n",
        "\tH=O(C,A[F]['past_grades'],A[F]['required_grades'],A[F]['hours']);return H\n",
        "T={'type':'service_account','project_id':'maximise-uk','private_key_id':'ee4f4bfedd72bcc729c76c1e0c67d5c01e5b96b9','private_key':'-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDZtZE8B2j6HUFd\\nLpmF2EoKZmqpVlwLR/ymi8U+06DZYlgL6KW+cjArrxglibMw6p8shgJxkFh5DZXS\\nk02wPCJrmKC+7wIIhPGiTHs0ji2b7RisEZl4Vgu2cdIR5IowMtds6HxhqjeCdVc4\\nIZ5VeiAqyA9gQW/thcTG7OcX0tcEynOYz9KuaCnWZYgG93Tl+aQQKm+mCsu3GleV\\ngXklS0sjB9HkevLaxcQLoCcg68Se7rSSWSrBguOSZ3SPjdvgJpsr09UoTA+9Spbu\\nRpC9avXoxrA0Tx+X0Z9rvRF8jYxOQwL2OkLCrpK3TCYCarbLUqax0oKtZ0LpBDcy\\nke/efi3zAgMBAAECggEAJ9VPwHL+oxytM/Ztwo6DZYm9pEQXzTybnoFeUpN4D64t\\nu+gSQ1kzNRrxSRT7w0x6WTQfyFWHyoZQzlmDUmZ+Sb+AUc77SUHB0Fc8B66n66qi\\n5ADIWrsro3MJ45o0KoNy5QtYjqoNRAJiNfP4u1z/+7PlFFCEwSnDij4YPkSmcMqf\\nnHyUPwxPvcUp2CAkeKjrV3UXEjdQ0wkh4hv6yMcXnGGDNknwEAEQ7may+BA81eAW\\nYky+ItP4qAauXHxJQBNG9iy9Win+BXQzFanF3ZmpyRtPjsfShuuFUNRncDt64E80\\nO7esMEQdjIlhMeSwZkWVob1U0l7nH5PCyRjfOwLxIQKBgQDu6Oq2eFmuUchBTZGa\\na/gAQ171g3dPCA4nhMoZM+beJM7tKrpTGb2S0B5yHpBd8llWkBIHnmEoFgPOZgPa\\nIt2GEK/ntOsvM4DYUSA6EizFUwLSLUDDIE34mvPehfakLM8Wh0Li/clzlZ58pvBv\\nhkVl3P/WBLLV8dDTalCNtGgS8QKBgQDpSGkecH/JuAwGB47fxoOdWCzs8f+DjP8P\\nRH3MQNtwp7DSSLRXNc9niQM/Ot1Fc8DOvxwxxUyR9iMqcHKiiPJsts4HItHq/WlR\\nxyAoRNGewKdk+Y4hZhIh0rEna8cce9ggNRGiw8HK2g2GnbomPj3eJdK5/MNWmkT+\\nyBIQ+a8HIwKBgA0fnkUHt2Vr+KQdrrHc3HKnQMAbyKH+v0hMcw2PXE83lmZQwotu\\nDovSAtoh86w1c9LddyAUAyJAk1TzJaMF50VGBWOk/IZLPfij/DE0bmEofi8tbTFK\\nxP2zBVJj6Xh7PaTvKS1u43IF9f7C7NIzffxqd2M6Ptihv+bdIC+oiU8BAoGBAOWT\\nzV+XdysdZTfJ2GGBC6WdURkeT0c3SwvLa8HHUi3b2bgYtOHeou5ReFCRrZDcCbNt\\ngGG6uVAr2w+4+hfajjlO7hM3wT5xhWRlgtAeaezBy/sjXSyhNtbyckVJW/o8JsYL\\nc/+qht0LGqSQNNHODzTAJFHE3rgruhrC6oSqNAXhAoGAXzB4POvZDXNTNRIAhMJ4\\no1PCooAq6K3WmGyAOV7+hQxS9IyShhIIqTG3B+fXoEgz/aaHwp+w1c83MSiiQWH1\\nZh0mB/Eer50iEPfECyhF8sPTW+Hk5KMUQSTZkkVximpQ7rszrb4JOrsjegCBP01s\\nOynEJrkUc6IZH/a/LLy1+90=\\n-----END PRIVATE KEY-----\\n','client_email':'firebase-adminsdk-zduqr@maximise-uk.iam.gserviceaccount.com','client_id':'101775960412756890600','auth_uri':'https://accounts.google.com/o/oauth2/auth','token_uri':'https://oauth2.googleapis.com/token','auth_provider_x509_cert_url':'https://www.googleapis.com/oauth2/v1/certs','client_x509_cert_url':'https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-zduqr%40maximise-uk.iam.gserviceaccount.com'}\n",
        "with open(a,'w')as U:dump(T,U)\n",
        "V=G.Certificate(a)\n",
        "C=I(V,{'storageBucket':'maximise-uk.appspot.com'},name='storage')\n",
        "W=H.bucket(app=C)\n",
        "for E in A(5,9):X=W.blob(f\"model_attainment_{E}.h5\");K(X.generate_signed_url(F(seconds=300),method='GET'),f\"model_attainment_{E}.h5\")\n",
        "C=Flask(__name__)\n",
        "@C.route('/',methods=['POST'])\n",
        "def b():A=L.get_json();B=P(A);return str({'output':B.tolist()})\n",
        "M(target=C.run,kwargs={'host':'0.0.0.0','port':80}).start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
